# LangSmith Overview

LangSmith is a platform by LangChain that helps developers **debug**, **monitor**, and **evaluate** Large Language Model (LLM) applications â€” especially those built with LangChain.

It acts like an **"observability layer"** for AI-powered apps, giving you detailed insights into:
- Which prompts were sent to the model
- How the model responded
- How tools were used during execution
- Performance metrics like latency and token usage
- User feedback and evaluation results

---

## âœ¨ Key Features

### 1. **Tracing**
Record every step of an AI application's execution.
- See each input, output, and intermediate step
- Inspect prompt templates and final rendered prompts
- Debug issues faster when the app misbehaves

### 2. **Evaluation**
Test different versions of prompts, tools, and chains.
- Compare model responses
- Use automated scoring or human feedback
- Identify which changes improve results

### 3. **Monitoring**
Track real-time usage and quality.
- Watch latency and token consumption
- Spot performance regressions
- Identify failure patterns early

---

## ðŸš€ Why Use LangSmith?

Without LangSmith:
- You have little visibility into how the LLM made a decision
- Debugging is slow and painful
- You canâ€™t easily compare changes

With LangSm
